{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f052f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burger Singh\\AppData\\Local\\Temp\\ipykernel_7108\\3635725759.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=r\"C:\\Users\\Burger Singh\\Downloads\\chromedriver_win32 (4)\\chromedriver.exe\")  # specify the path to your chromedriver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Store Name  \\\n",
      "0             Sector 50, Noida   \n",
      "1             Sector 50, Noida   \n",
      "2             Sector 50, Noida   \n",
      "3             Sector 50, Noida   \n",
      "4  West Patel Nagar, New Delhi   \n",
      "5  West Patel Nagar, New Delhi   \n",
      "6  West Patel Nagar, New Delhi   \n",
      "7  West Patel Nagar, New Delhi   \n",
      "\n",
      "                                              Offer                  Code  \n",
      "0                                50% OFF up to ₹100    use code WELCOME50  \n",
      "1                                50% OFF up to ₹100     use code ZOMPAYTM  \n",
      "2                                20% OFF up to ₹150    use code INDUSFEST  \n",
      "3  50% OFF up to ₹100 + up to ₹150 LazyPay cashback  use code LAZYPAYFEST  \n",
      "4                                50% OFF up to ₹100    use code WELCOME50  \n",
      "5                                     Flat ₹150 OFF      use code FLAT150  \n",
      "6                                60% OFF up to ₹120     use code ZOMPAYTM  \n",
      "7                                20% OFF up to ₹150    use code INDUSFEST  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=r\".....................................\")  # specify the path to your chromedriver\n",
    "\n",
    "store_urls = [\".........................................................\"]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for url in store_urls:\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Find store name using Selenium and XPath\n",
    "    store_name = driver.find_element(\"xpath\",'/html/body/div[1]/div/main/div/section[3]/section/section/div/div/section[1]/a').text\n",
    "\n",
    "    offers = [offer.get_text() for offer in soup.find_all(\"div\",attrs={\"class\": \"sc-1a03l6b-0 lkqupg\"})]\n",
    "    codes = [code.get_text() for code in soup.find_all(\"div\",attrs={\"class\": \"sc-1a03l6b-1 kvnZBD\"})]\n",
    "    \n",
    "    max_len = max(len(offers), len(codes))\n",
    "    store_names = [store_name]*max_len\n",
    "    \n",
    "    if len(offers) < max_len:\n",
    "        offers += [None]*(max_len - len(offers))\n",
    "    if len(codes) < max_len:\n",
    "        codes += [None]*(max_len - len(codes))\n",
    "    \n",
    "    for data in zip(store_names, offers, codes):\n",
    "        all_data.append(data)\n",
    "\n",
    "df = pd.DataFrame(all_data, columns=['Store Name', 'Offer', 'Code'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()  # don't forget to quit the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30523a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from warnings import filterwarnings\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Set the Edge driver path\n",
    "path = r\"C:\\Users\\Burger Singh\\Downloads\\edgedriver_win64\\msedgedriver.exe\"\n",
    "\n",
    "op = webdriver.EdgeOptions()\n",
    "\n",
    "url = 'https://www.zomato.com/ncr/the-momo-company-tilak-nagar-new-delhi/order'\n",
    "\n",
    "# Start the Edge driver\n",
    "driver = webdriver.Edge(path, options=op)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "content = page.content\n",
    "soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(10.0)\n",
    "\n",
    "driver.find_element(\"xpath\", \"/html/body/div[1]/div/main/div/article/div/section/section/div[2]/h2/a\").click()\n",
    "\n",
    "time.sleep(5.0)\n",
    "\n",
    "# The rest of your code remains the same\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "category = driver.find_element(\"xpath\",\"/html/body/div[1]/div/main/div/section[4]/section/section[1]/p[1]\")\n",
    "\n",
    "li=[]\n",
    "try:\n",
    "    for i in range(1,100):\n",
    "        li.append(driver.find_element(\"xpath\",\"/html/body/div[1]/div/main/div/section[4]/section/section[1]/p[{}]\".format(i)).text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "li2 = []\n",
    "for i in li:\n",
    "    value = i\n",
    "    value = value[-3:-1]\n",
    "    value = [int(i) for i in value.split('(') if i.isdigit()]\n",
    "    li2.append(value)\n",
    "li3 = []\n",
    "\n",
    "for i in li2:\n",
    "    for j in i:\n",
    "        li3.append(j)\n",
    "        \n",
    "\n",
    "res_list = []\n",
    "for i in range(0, len(li)):\n",
    "    res_list.append((li[i]+\", \" )* li3[i])\n",
    "nw = []\n",
    "for i in range(len(res_list)):\n",
    "    nw.append(res_list[i])\n",
    "abc=[]\n",
    "for i in nw:\n",
    "    abc.append(str(i))\n",
    "ab = []\n",
    "for i in abc:\n",
    "    ab.append(i.split(\",\"))\n",
    "new = list(np.concatenate(ab))\n",
    "final_cat = []\n",
    "final_cat = [x for x in new if x != ' ']\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "\n",
    "page = requests.get('https://www.zomato.com/ncr/the-momo-company-tilak-nagar-new-delhi/order', headers=headers)\n",
    "\n",
    "content = page.content\n",
    "soup = BeautifulSoup(content,\"lxml\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for i in range(len(soup.find_all(\"span\",attrs={\"class\": \"sc-17hyc2s-1 cCiQWA\"}))):\n",
    "    li.append(soup.find_all(\"span\",attrs={\"class\": \"sc-17hyc2s-1 cCiQWA\"})[i].get_text())\n",
    "\n",
    "    \n",
    "\n",
    "p = []\n",
    "\n",
    "for i in range(len(soup.find_all(\"h4\",attrs={\"class\": \"sc-1s0saks-15 iSmBPS\"}))):\n",
    "    p.append(soup.find_all(\"h4\",attrs={\"class\": \"sc-1s0saks-15 iSmBPS\"})[i].get_text())\n",
    "    \n",
    "\n",
    "g = []\n",
    "\n",
    "for i in range(len(soup.find_all(\"p\",attrs={\"class\": \"sc-1s0saks-12 hcROsL\"}))):\n",
    "    g.append(soup.find_all(\"p\",attrs={\"class\": \"sc-1s0saks-12 hcROsL\"})[i].get_text())\n",
    "\n",
    "    \n",
    "    \n",
    "BS = pd.DataFrame()\n",
    "BS['Category'] = final_cat\n",
    "BS['Item'] = p\n",
    "BS['Price'] = li\n",
    "BS['Product Description'] = g\n",
    "BS['Res Name'] = \"The Momo Company\"\n",
    "BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da06b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
